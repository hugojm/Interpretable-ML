{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "69abe50a",
   "metadata": {},
   "source": [
    "# FooLS - Fooling LIME and SHAP Framework\n",
    "This work is based on Dylan et al. who have proven that perturbation-based post-hoc explanation methods (in particular LIME and SHAP) are not reliable since an adversary could create a model that is extremely biased but will nonetheless be regarded as unbiased if explained by perturbation-based post-hoc explanation. Dylan et al. have proposed an approach that makes it possible to create a new adversarial model which succesfully hides the bias of a model when LIME or SHAP are applied on it, respectively. Our framework allows it to easily create these adversarial models on the fly. In Addition to that we have also examined the influence of the different parameters and perturbation methods on LIME and SHAP. We have also added three new datasets to evaluate these methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "907320d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning) \n",
    "\n",
    "from adversarial_models import * \n",
    "from utils import *\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import lime\n",
    "import lime.lime_tabular\n",
    "import shap\n",
    "from copy import deepcopy\n",
    "from sklearn.inspection import PartialDependenceDisplay\n",
    "from pdpbox import pdp, get_dataset, info_plots\n",
    "\n",
    "from sklearn.cluster import Birch\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4210f67",
   "metadata": {},
   "source": [
    "## Partical Dependence Plots\n",
    "We have extended the framework by PDP but have been unable to fool PDP. However, in theory this should be possible since PDP also uses perturbations when fixing all non-interested features and changing the feature(s) of interest. There are other approaches that claim to have successfully fooled PDP by data poisening (\"Fooling Partial Dependence via Data Poisoning\", Baniecki et al.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99b24be5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PDP:\n",
    "    @staticmethod\n",
    "    def calculate_ice(model, X, s):\n",
    "        \"\"\"\n",
    "        Takes the input data and expands the dimensions from (num_instances, num_features) to (num_instances,\n",
    "        num_instances, num_features). For the current instance i and the selected feature index s, the\n",
    "        following equation is ensured: X_ice[i, :, s] == X[i, s].\n",
    "\n",
    "        Parameters:\n",
    "            model: Classifier which can call a predict method.\n",
    "            X (np.array with shape (num_instances, num_features)): Input data.\n",
    "            s (int): Index of the feature x_s.\n",
    "\n",
    "        Returns:\n",
    "            X_ice (np.array with shape (num_instances, num_instances, num_features)): Changed input data w.r.t. x_s.\n",
    "            y_ice (np.array with shape (num_instances, num_instances)): Predicted data.\n",
    "        \"\"\"\n",
    "        num_instances = len(X)\n",
    "        num_features = len(X[0])\n",
    "        unique_values_s = X[:,s]\n",
    "        X_ice = np.empty((num_instances, num_instances, num_features))\n",
    "        for i in range(0, num_instances):\n",
    "            for j in range(0, num_instances):\n",
    "                X_ice[i][j] = X[i]\n",
    "                for k in range(0, num_features):\n",
    "                    if k != s:\n",
    "                        X_ice[i][j][k] = X[j][k]\n",
    "        y_ice = np.empty((num_instances, num_instances))\n",
    "        for i in range(0, num_instances):\n",
    "            y_ice[i] = model.predict(X_ice[i])\n",
    "        return X_ice, y_ice\n",
    "\n",
    "    @staticmethod\n",
    "    def prepare_ice(model, X, s, centered=False):\n",
    "        \"\"\"\n",
    "        Uses `calculate_ice` to retrieve plot data.\n",
    "\n",
    "        Parameters:\n",
    "            model: Classifier which can call a predict method.\n",
    "            X (np.array with shape (num_instances, num_features)): Input data.\n",
    "            s (int): Index of the feature x_s.\n",
    "            centered (bool): Whether c-ICE should be used or not.\n",
    "\n",
    "        Returns:\n",
    "            all_x (list or 1D np.ndarray): List of lists of the x values.\n",
    "            all_y (list or 1D np.ndarray): List of lists of the y values.\n",
    "                Each entry in `all_x` and `all_y` represents one line in the plot.\n",
    "        \"\"\"\n",
    "        num_instances = len(X)\n",
    "        X_ice, all_y = PDP.calculate_ice(model, X, s)\n",
    "        all_y = all_y.transpose()\n",
    "        all_x = np.empty((num_instances, num_instances))\n",
    "        for i in range(num_instances):\n",
    "            for j in range(num_instances):\n",
    "                all_x[i][j] = X_ice[i][j][s]\n",
    "        all_x = all_x.transpose()\n",
    "        for i in range(num_instances):\n",
    "            all_x[i], all_y[i] = zip(*sorted(zip(all_x[i], all_y[i])))\n",
    "        if centered == True:\n",
    "            for i in range(num_instances):\n",
    "                center_value = all_y[i][0]\n",
    "                for j in range(num_instances):\n",
    "                    all_y[i][j] = all_y[i][j] - center_value\n",
    "        return all_x, all_y\n",
    "\n",
    "    @staticmethod\n",
    "    def plot_ice(model, dataset, X, s, centered=False):\n",
    "        \"\"\"\n",
    "        Creates a plot object and fills it with the content of `prepare_ice`.\n",
    "        Note: `show` method is not called.\n",
    "\n",
    "        Parameters:\n",
    "            model: Classifier which can call a predict method.\n",
    "            dataset (utils.Dataset): Used dataset to train the model. Used to receive the labels.\n",
    "            s (int): Index of the feature x_s.\n",
    "            centered (bool): Whether c-ICE should be used or not.\n",
    "\n",
    "        Returns:\n",
    "            plt (matplotlib.pyplot or utils.styled_plot.plt)\n",
    "        \"\"\"\n",
    "        plt.figure()\n",
    "        all_x, all_y = PDP.prepare_ice(model, X, s, centered)\n",
    "        plt.plot(all_x, all_y, alpha=0.2)\n",
    "        x_label = dataset.get_input_labels()[s]\n",
    "        y_label = dataset.get_output_label()\n",
    "        plt.xlabel(x_label)\n",
    "        plt.ylabel(y_label)\n",
    "\n",
    "        return plt\n",
    "\n",
    "    @staticmethod\n",
    "    def prepare_pdp(model, X, s):\n",
    "        \"\"\"\n",
    "        Uses `calculate_ice` to retrieve plot data for PDP.\n",
    "\n",
    "        Parameters:\n",
    "            model: Classifier which can call a predict method.\n",
    "            X (np.ndarray with shape (num_instances, num_features)): Input data.\n",
    "            s (int): Index of the feature x_s.\n",
    "\n",
    "        Returns:\n",
    "            x (list or 1D np.ndarray): x values of the PDP line.\n",
    "            y (list or 1D np.ndarray): y values of the PDP line.\n",
    "        \"\"\"\n",
    "        x = []\n",
    "        y = []\n",
    "        num_instances = len(X)\n",
    "        X_ice, y_ice = PDP.calculate_ice(model, X, s)\n",
    "        for i in range(num_instances):\n",
    "            x.append(X_ice[i][i][s])\n",
    "            sum = 0\n",
    "            for j in range(num_instances):\n",
    "                sum += y_ice[i,j]\n",
    "            y.append(sum/num_instances)\n",
    "        x, y = zip(*sorted(zip(x, y)))\n",
    "        x = np.asarray(x)\n",
    "        y = np.asarray(y)\n",
    "        return x, y\n",
    "\n",
    "    @staticmethod\n",
    "    def plot_pdp(model, X, s):\n",
    "        \"\"\"\n",
    "        Creates a plot object and fills it with the content of `prepare_pdp`.\n",
    "        Note: `show` method is not called.\n",
    "\n",
    "        Parameters:\n",
    "            model: Classifier which can call a predict method.\n",
    "            dataset (utils.Dataset): Used dataset to train the model. Used to receive the labels.\n",
    "            s (int): Index of the feature x_s.\n",
    "            centered (bool): Whether c-ICE should be used or not.\n",
    "\n",
    "        Returns:\n",
    "            plt (matplotlib.pyplot or utils.styled_plot.plt)\n",
    "        \"\"\"\n",
    "        plt.figure()\n",
    "\n",
    "        x, y = PDP.prepare_pdp(model, X, s)\n",
    "        plt.plot(x, y)\n",
    "        return plt\n",
    "\n",
    "    @staticmethod\n",
    "    def plot_pdp_all(model, X, feature_names):\n",
    "        \"\"\"\n",
    "        Creates a plot object and fills it with the content of `prepare_pdp`.\n",
    "        Note: `show` method is not called.\n",
    "\n",
    "        Parameters:\n",
    "            model: Classifier which can call a predict method.\n",
    "            dataset (utils.Dataset): Used dataset to train the model. Used to receive the labels.\n",
    "            s (int): Index of the feature x_s.\n",
    "            centered (bool): Whether c-ICE should be used or not.\n",
    "\n",
    "        Returns:\n",
    "            plt (matplotlib.pyplot or utils.styled_plot.plt)\n",
    "        \"\"\"\n",
    "        plt.figure()\n",
    "        fig, ax = plt.subplots(nrows=3, ncols=5)\n",
    "        fig.set_size_inches(18.5, 10.5)\n",
    "        s = range(X.shape[1])\n",
    "        i = 0\n",
    "        for row in ax:\n",
    "            for col in row:\n",
    "                if i < X.shape[1]:\n",
    "                    x, y = PDP.prepare_pdp(model, X, s[i])\n",
    "                    col.plot(x, y)\n",
    "                    col.set_xlabel(list(feature_names.keys())[list(feature_names.values()).index(i)])\n",
    "                    i +=1\n",
    "\n",
    "        return plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cfb676a",
   "metadata": {},
   "source": [
    "## FooLS Framework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d598ef6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Constants that are used distinguish between the different modes of our framework\n",
    "METHOD_LIME = 0\n",
    "METHOD_SHAP = 1\n",
    "ONE_EXISTING_COLUMN = 0\n",
    "ONE_UNCORRELATED_COLUMN = 1\n",
    "TWO_UNCORRELATED_COLUMN = 2\n",
    "#The framework class that takes in certain parameters and provides functions to generate adversarial models \n",
    "#which can fool LIME and SHAP, respectively. It also provides a function that plots the PDP. \n",
    "class FooLS:\n",
    "    def __init__(self, protected_class_name, protected_class_name_value, unprotected_class_name, unprotected_class_name_value, column_flag, pd_dataset, categorical_feature_names=[], correlated_column=None, seed=None, perturbation_lime_mode=PERTURB_LIME_MODE_STD, perturbation_shap_mode=PERTURB_SHAP_MODE_STD, unrelated_column1_name='unrelated_column1', unrelated_column2_name='unrelated_column2'):\n",
    "        \"\"\"\n",
    "        Initializes a FooLS object which can be used to create adversarial models that fool LIME and SHAP.\n",
    "        Also, a PDP function is provided by this class\n",
    "\n",
    "        Parameters:\n",
    "            protected_class_name (str): The name of the feature/class that the discriminatory model uses to make its decision and which should be hidden (e.g. 'race')\n",
    "            protected_class_name_value (list): A list of values which should be treated as the reason for making the discriminatory decisions (e.g. ['black', 'hispanic'])\n",
    "            unprotected_class_name (str): The name of the feature/class that is the y-value.\n",
    "            unprotected_class_name_value (list): A List of values which should lead to a positive outcome in the y-value.\n",
    "            column_flag (int): The flag that decides if the bias should be shifted towards another existing column, a new uncorrelated column, or two new uncorrelated columns\n",
    "            pd_dataset (pandas.Dataframe): Panda dataframe of the used dataset.\n",
    "            categorical_feature_names (list): List of names of features/classes that are categorical (e.g. (0,1), (HIGH, LOW)).\n",
    "            correlated_column (str): If you want to use an existing feature/class then you need to pass the name of that column to this function.\n",
    "            seed (int): numpy seed to fix randomness.\n",
    "            perturbation_lime_mode (int): Set the perturbation technique that should be used to generate OOD samples (standard, soft brownian offset, gaussian hypersperic offset).\n",
    "            perturbation_shap_mode (int): Set the perturbation technique that should be used to generate the background perturbation (standard, birch).\n",
    "            unrelated_column1_name (str): Name of the new uncorrelated feature/class that will be added to the dataset if the corresponding mode is chosen.\n",
    "            unrelated_column2_name (str): Name of the new uncorrelated feature/class that will be added to the dataset if the corresponding mode is chosen.\n",
    "        \"\"\"\n",
    "        if column_flag == ONE_EXISTING_COLUMN and correlated_column == None:\n",
    "            raise Exception(\"You need to provide a column name if you want to shift importance\\\n",
    "                            to an existing feature.\")\n",
    "        if not isinstance(pd_dataset, pd.DataFrame):\n",
    "            raise Exception(\"The dataset needs to be a Pandas Dataframe.\")\n",
    "        if correlated_column is not None and correlated_column not in pd_dataset.columns:\n",
    "            raise Exception(\"You need to provide an existing column that is part of the dataset if you want to use\\\n",
    "                            an existing feature\")\n",
    "        if column_flag not in [ONE_EXISTING_COLUMN,ONE_UNCORRELATED_COLUMN,TWO_UNCORRELATED_COLUMN]:\n",
    "            raise Exception(\"Only three modes available: Use an existing feature, a new uncorrelated feature,\\\n",
    "                            or two new uncorrelated features.\")\n",
    "        if perturbation_lime_mode not in [0,1,2] or perturbation_shap_mode not in [0,1]:\n",
    "            raise Exception(\"Only three perturbation methods available for each LIME and SHAP.\")\n",
    "        if not isinstance(protected_class_name, str) or not isinstance(unprotected_class_name, str):\n",
    "            raise Exception(\"You need to provide the names of the protected and unprotected features.\")\n",
    "        if not isinstance(protected_class_name_value, list) or not isinstance(unprotected_class_name_value, list):\n",
    "            raise Exception(\"You need to provide the values of the bias-prone feature which should lead to\\\n",
    "                            discrimination and the values of the non-bias-prone feature which would lead to\\\n",
    "                            a fair classification.\")\n",
    "        \n",
    "        self.seed = np.random.randint(0xffffffff) if seed == None else seed\n",
    "        self.protected_class_name = protected_class_name\n",
    "        self.protected_class_name_value = protected_class_name_value\n",
    "        self.unprotected_class_name = unprotected_class_name\n",
    "        self.unprotected_class_name_value = unprotected_class_name_value\n",
    "        self.column_flag = column_flag\n",
    "        self.correlated_column = correlated_column\n",
    "        self.categorical_feature_names = categorical_feature_names\n",
    "        self.pd_dataset = pd_dataset\n",
    "        self.unrelated_column1_name = unrelated_column1_name\n",
    "        self.unrelated_column2_name = unrelated_column2_name\n",
    "        self.perturbation_lime_mode = perturbation_lime_mode\n",
    "        self.perturbation_shap_mode = perturbation_shap_mode\n",
    "        \n",
    "        np.random.seed(self.seed)\n",
    "        self.setup()\n",
    "    #We expect that NAs or other undesireble entries have been removed\n",
    "    #protected class is the class that the discriminatoy model should use to classify (e.g race).\n",
    "    #unprotected class is the class that is used as a label (e.g credit score class).\n",
    "    #For both classes we iterate through the given (un)protected_class_name_values and replace the value of the columns with 1 if it is part of those classes or 0 if it is not\n",
    "    #example: column 'race' is the protected class and protected_class_name_values is a list of ['African', 'Hispanic']. All race column entries are now either replaced by 1 if that entry is African or Hispanic or 0 if its not\n",
    "    def preprocess_data(self):\n",
    "        X = self.pd_dataset\n",
    "        y = np.array([1 if val in self.unprotected_class_name_value else 0 for val in X[self.unprotected_class_name]])\n",
    "        X = X.drop(self.unprotected_class_name, axis=1)\n",
    "        sens = X.pop(self.protected_class_name)\n",
    "        X = pd.get_dummies(X)\n",
    "        buffer = [np.array(pd.get_dummies(sens).pop(x)) for x in self.protected_class_name_value]\n",
    "        sensitive_attr = np.array([0]*len(sens))\n",
    "        for attr in buffer:\n",
    "            sensitive_attr = sensitive_attr + attr\n",
    "        X[self.protected_class_name] = sensitive_attr\n",
    "        return X, y\n",
    "    #Here we create either unrelated columns that are used to explain our discriminatoy model\n",
    "    #or we use an existing feature column_flag\n",
    "    #ONE_EXISTING_COLUMN := use existing feature (needs 'correlated_column' to be set)\n",
    "    #ONE_UNCORRELATED_COLUMN := 1 unrelated column\n",
    "    #TWO_UNCORRELATED_COLUMN := 2 unrelated columns\n",
    "    def setup(self):\n",
    "        X, y = self.preprocess_data()\n",
    "        self.unrelated_indcs = []\n",
    "        self.X, self.y = X,y\n",
    "        \n",
    "        if self.column_flag == ONE_EXISTING_COLUMN:\n",
    "            self.unrelated_indcs.append(X.columns.get_loc(self.correlated_column))\n",
    "            if self.correlated_column not in self.categorical_feature_names:\n",
    "                self.categorical_feature_names.append(self.correlated_column)\n",
    "        elif self.column_flag == ONE_UNCORRELATED_COLUMN:\n",
    "            X[self.unrelated_column1_name] = np.random.choice([0,1],size=X.shape[0])\n",
    "            self.unrelated_indcs.append(X.columns.get_loc(self.unrelated_column1_name))\n",
    "            self.categorical_feature_names.append(self.unrelated_column1_name)\n",
    "        elif self.column_flag == TWO_UNCORRELATED_COLUMN:\n",
    "            X[self.unrelated_column1_name] = np.random.choice([0,1],size=X.shape[0])\n",
    "            self.unrelated_indcs.append(X.columns.get_loc(self.unrelated_column1_name))\n",
    "            X[self.unrelated_column2_name] = np.random.choice([0,1],size=X.shape[0])\n",
    "            self.unrelated_indcs.append(X.columns.get_loc(self.unrelated_column2_name))\n",
    "            self.categorical_feature_names.append(self.unrelated_column1_name)\n",
    "            self.categorical_feature_names.append(self.unrelated_column2_name)\n",
    "        \n",
    "        #Save the feature column names\n",
    "        self.features = [c for c in X]\n",
    "        self.protected_indc = self.features.index(self.protected_class_name)\n",
    "        \n",
    "        #String data will be split into n different columns with one-hot encoding\n",
    "        #example: column 'sex' can either have value 'male' or 'female'. That column will be split up into two columns 'sex_male' and 'sex_female' which contain value 0 if an entry is not of that specific class or 1 if it is\n",
    "        new_categorical_feature_names = []\n",
    "        for cat in self.categorical_feature_names:\n",
    "            if cat not in X.columns.tolist():\n",
    "                new_categorical_feature_names += [col for col in X.columns.tolist() if col.startswith(cat+'_')]\n",
    "            else:\n",
    "                new_categorical_feature_names.append(cat)\n",
    "        self.categorical_feature_names = new_categorical_feature_names\n",
    "        \n",
    "        #Convert pandas dataframe to numpy array\n",
    "        X = X.values\n",
    "        #extract the indeces of the categorical feature columns\n",
    "        self.categorical_feature_indcs = [self.features.index(c) for c in self.categorical_feature_names]\n",
    "        \n",
    "        # Split the data and normalize\n",
    "        self.xtrain ,self.xtest ,self.ytrain ,self.ytest = train_test_split(X,y)\n",
    "        xtest_not_normalized = deepcopy(self.xtest)\n",
    "        ss = StandardScaler().fit(self.xtrain)\n",
    "        self.xtrain = ss.transform(self.xtrain)\n",
    "        self.xtest = ss.transform(self.xtest)\n",
    "        \n",
    "    class discriminatory_model:\n",
    "        def __init__(self, protected_indc):\n",
    "            self.protected_indc = protected_indc\n",
    "        def predict(self,X):\n",
    "            #Since we normalize between -1 and 1 the 'True' and 'False'\n",
    "            #values will always be bigger or smaller than 0, respectively\n",
    "            return np.array([0 if x[self.protected_indc] > 0 else 1 for x in X])\n",
    "\n",
    "        def predict_proba(self, X): \n",
    "            return one_hot_encode(self.predict(X))\n",
    "\n",
    "        def score(self, X,y):\n",
    "            return np.sum(self.predict(X)==y) / len(X)\n",
    "    \n",
    "    class innocuous_model_psi:\n",
    "        def __init__(self, unrelated_indcs):\n",
    "            self.unrelated_indcs = unrelated_indcs\n",
    "        #Since we normalize between -1 and 1 the 'True' and 'False'\n",
    "        #values will always be bigger or smaller than 0, respectively\n",
    "        def predict(self,X):\n",
    "            return np.array([0 if x[self.unrelated_indcs[0]] > 0 else 1 for x in X])\n",
    "\n",
    "        def predict_proba(self, X): \n",
    "            return one_hot_encode(self.predict(X))\n",
    "\n",
    "        def score(self, X,y):\n",
    "            return np.sum(self.predict(X)==y) / len(X)\n",
    "    \n",
    "    class innocuous_model_psi_two:\n",
    "        def __init__(self, unrelated_indcs):\n",
    "            self.unrelated_indcs = unrelated_indcs\n",
    "        #When using two new uncorrelated features then the prediction is the xor of each feature entry\n",
    "        def predict_proba(self, X):\n",
    "            A = np.where(X[:,self.unrelated_indcs[0]] > 0, 1, 0)\n",
    "            B = np.where(X[:,self.unrelated_indcs[1]] > 0, 1, 0)\n",
    "            preds = np.logical_xor(A, B).astype(int)\n",
    "            return one_hot_encode(preds)\n",
    "    \n",
    "    def LIME_execute(self, sample_around_instance=True, discretize_continuous=False, perturbation_std=0.3, perturbation_multiplier=30, rf_estimators=100, verbose=True):\n",
    "        \"\"\"\n",
    "        Create the adversarial model that fools LIME by replacing the biased model with a model that\n",
    "        distinguishes between out-of-distribution samples and inside-distribution samples which still\n",
    "        leads to the same prediction but different explanation.\n",
    "\n",
    "        Parameters:\n",
    "            sample_around_instance (bool)\n",
    "            discretize_continuous (bool)\n",
    "            perturbation_std (float)\n",
    "            perturbation_multiplier (float)\n",
    "            rf_estimators (int)\n",
    "            verbose (bool)\n",
    "        \"\"\"\n",
    "        if self.column_flag == ONE_EXISTING_COLUMN or self.column_flag == ONE_UNCORRELATED_COLUMN:\n",
    "            #Create the adversarial LIME model\n",
    "            adv_lime = Adversarial_Lime_Model(self.discriminatory_model(self.protected_indc), self.innocuous_model_psi(self.unrelated_indcs), perturbation_std=perturbation_std).train(self.xtrain, self.ytrain, categorical_features=self.categorical_feature_indcs, feature_names=self.features, perturbation_multiplier=perturbation_multiplier, rf_estimators=rf_estimators, perturbation_mode=self.perturbation_lime_mode)\n",
    "            #Explain the newly created adversarial LIME model\n",
    "            adv_explainer = lime.lime_tabular.LimeTabularExplainer(self.xtrain, sample_around_instance=sample_around_instance, feature_names=adv_lime.get_column_names(), categorical_features=self.categorical_feature_indcs, discretize_continuous=discretize_continuous)\n",
    "\n",
    "            #Extract the explanations from the explainer\n",
    "            explanations = []\n",
    "            for i in range(self.xtest.shape[0]):\n",
    "                explanations.append(adv_explainer.explain_instance(self.xtest[i], adv_lime.predict_proba).as_list())\n",
    "\n",
    "            if verbose == True:\n",
    "                # Display Results\n",
    "                print (\"LIME Ranks and Pct Occurances (1 corresponds to most important feature) for one unrelated feature:\")\n",
    "                print (experiment_summary(explanations, self.features))\n",
    "                print (\"Fidelity:\", round(adv_lime.fidelity(self.xtest),2))\n",
    "\n",
    "        if self.column_flag == TWO_UNCORRELATED_COLUMN:\n",
    "            #Same as above with the difference that we use two new uncorrelated features\n",
    "            adv_lime = Adversarial_Lime_Model(self.discriminatory_model(self.protected_indc), self.innocuous_model_psi_two(self.unrelated_indcs), perturbation_std=perturbation_std).train(self.xtrain, self.ytrain, categorical_features=self.categorical_feature_indcs, feature_names=self.features, perturbation_multiplier=perturbation_multiplier, rf_estimators=rf_estimators, perturbation_mode=self.perturbation_lime_mode)\n",
    "            adv_explainer = lime.lime_tabular.LimeTabularExplainer(self.xtrain, feature_names=adv_lime.get_column_names(), categorical_features=self.categorical_feature_indcs, discretize_continuous=discretize_continuous)\n",
    "            \n",
    "            explanations = []\n",
    "            for i in range(self.xtest.shape[0]):\n",
    "                explanations.append(adv_explainer.explain_instance(self.xtest[i], adv_lime.predict_proba).as_list())\n",
    "\n",
    "            if verbose == True:\n",
    "                print (\"LIME Ranks and Pct Occurances two unrelated features:\")\n",
    "                print (experiment_summary(explanations, self.features))\n",
    "                print (\"Fidelity:\", round(adv_lime.fidelity(self.xtest),2))\n",
    "            \n",
    "        return adv_lime, experiment_summary(explanations, self.features)\n",
    "        \n",
    "    def SHAP_execute(self, cluster=10, perturbation_multiplier=30, rf_estimators=100, verbose=True):\n",
    "        \"\"\"\n",
    "        Create the adversarial model that fools SHAP by replacing the biased model with a model that\n",
    "        distinguishes between out-of-distribution samples and inside-distribution samples which still\n",
    "        leads to the same prediction but different explanation.\n",
    "\n",
    "        Parameters:\n",
    "            cluster (int)\n",
    "            perturbation_multiplier (int)\n",
    "            rf_estimators (int)\n",
    "            verbose (bool)\n",
    "        \"\"\"\n",
    "\n",
    "        if self.column_flag == ONE_EXISTING_COLUMN or self.column_flag == ONE_UNCORRELATED_COLUMN:\n",
    "            #Depending on the perturbation mode create a different background perturbation\n",
    "            if self.perturbation_shap_mode == PERTURB_SHAP_MODE_STD:\n",
    "                background_distribution = shap.kmeans(self.xtrain,cluster)\n",
    "            elif self.perturbation_shap_mode == PERTURB_SHAP_MODE_BIRCH:\n",
    "                birch = Birch().fit(self.xtrain)\n",
    "                background_distribution = birch.subcluster_centers_[:cluster]\n",
    "            #Create an adversarial model that can fool SHAP\n",
    "            adv_shap = Adversarial_Kernel_SHAP_Model(self.discriminatory_model(self.protected_indc), self.innocuous_model_psi(self.unrelated_indcs)).train(self.xtrain, self.ytrain, feature_names=self.features, n_kmeans=cluster, perturbation_multiplier=perturbation_multiplier, rf_estimators=rf_estimators, perturbation_mode=self.perturbation_shap_mode)\n",
    "            #Explain the adversarial model which leads to the explanation that hides the bias\n",
    "            adv_kerenel_explainer = shap.KernelExplainer(adv_shap.predict, background_distribution)\n",
    "            explanations = adv_kerenel_explainer.shap_values(self.xtest)\n",
    "\n",
    "            formatted_explanations = []\n",
    "            for exp in explanations:\n",
    "                formatted_explanations.append([(self.features[i], exp[i]) for i in range(len(exp))])\n",
    "\n",
    "            if verbose == True:\n",
    "                print (\"SHAP Ranks and Pct Occurances one unrelated features:\")\n",
    "                print (experiment_summary(formatted_explanations, self.features))\n",
    "                print (\"Fidelity:\",round(adv_shap.fidelity(self.xtest),2))\n",
    "                print ('---------------------')\n",
    "\n",
    "        if self.column_flag == TWO_UNCORRELATED_COLUMN:\n",
    "            #Same as above with the difference that we use two new uncorrelated features\n",
    "            if self.perturbation_shap_mode == PERTURB_SHAP_MODE_STD:\n",
    "                background_distribution = shap.kmeans(self.xtrain,cluster)\n",
    "            elif self.perturbation_shap_mode == PERTURB_SHAP_MODE_BIRCH:\n",
    "                birch = Birch().fit(self.xtrain)\n",
    "                background_distribution = birch.subcluster_centers_[:cluster]\n",
    "            \n",
    "            adv_shap = Adversarial_Kernel_SHAP_Model(self.discriminatory_model(self.protected_indc), self.innocuous_model_psi_two(self.unrelated_indcs)).train(self.xtrain, self.ytrain, feature_names=self.features, n_kmeans=cluster, perturbation_multiplier=perturbation_multiplier, rf_estimators=rf_estimators, perturbation_mode=self.perturbation_lime_mode)\n",
    "            adv_kerenel_explainer = shap.KernelExplainer(adv_shap.predict, background_distribution)\n",
    "            explanations = adv_kerenel_explainer.shap_values(self.xtest)\n",
    "\n",
    "            formatted_explanations = []\n",
    "            for exp in explanations:\n",
    "                formatted_explanations.append([(self.features[i], exp[i]) for i in range(len(exp))])\n",
    "\n",
    "            if verbose == True:\n",
    "                print (\"SHAP Ranks and Pct Occurances two unrelated features:\")\n",
    "                print (experiment_summary(formatted_explanations, self.features))\n",
    "                print (\"Fidelity:\",round(adv_shap.fidelity(self.xtest),2))\n",
    "                print ('---------------------')\n",
    "\n",
    "        #Get a bar-plot for better visualization\n",
    "        if verbose == True:\n",
    "            shap.summary_plot(explanations, feature_names=self.features, plot_type=\"bar\")\n",
    "        \n",
    "        return adv_shap, experiment_summary(formatted_explanations, self.features)\n",
    "            \n",
    "    def PDP_execute(self, fool_method=METHOD_LIME):\n",
    "        \"\"\"\n",
    "        Create the Partical Dependence Plot that shows feature importance of each feature.\n",
    "\n",
    "        Parameters:\n",
    "            fool_method (int)\n",
    "        \"\"\"\n",
    "        #Depending on the chosen mode either apply PDP on the adversarial\n",
    "        #LIME or SHAP model\n",
    "        if fool_method == METHOD_LIME:\n",
    "            adv_model, _ = self.LIME_execute(verbose=False)\n",
    "        elif fool_method == METHOD_SHAP:\n",
    "            adv_model, _ = self.SHAP_execute(verbose=False)\n",
    "        #Create name and index dictionary to label PDP\n",
    "        lista = list(self.features)\n",
    "        names = {}\n",
    "        for i in range(len(self.features)):\n",
    "            names[lista[i]] = i\n",
    "        if fool_method == METHOD_LIME:\n",
    "            print(\"PDP plot using the adversarial LIME model\")\n",
    "        elif fool_method == METHOD_SHAP:\n",
    "            print(\"PDP plot using the adversarial SHAP model\")\n",
    "        PDP.plot_pdp_all(adv_model, self.xtest, names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf83cc25",
   "metadata": {},
   "source": [
    "## COMPAS Dataset\n",
    "Check if our Framework gets similar results on the datasets provided in the paper - it does!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d22b331",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "compas_df = pd.read_csv(\"data/compas-scores-two-years.csv\", index_col=0)\n",
    "compas_df = compas_df.loc[(compas_df['days_b_screening_arrest'] <= 30) &\n",
    "            (compas_df['days_b_screening_arrest'] >= -30) &\n",
    "            (compas_df['is_recid'] != -1) &\n",
    "            (compas_df['c_charge_degree'] != \"O\") &\n",
    "            (compas_df['score_text'] != \"NA\")]\n",
    "compas_df['length_of_stay'] = (pd.to_datetime(compas_df['c_jail_out']) - pd.to_datetime(compas_df['c_jail_in'])).dt.days\n",
    "dataset = compas_df[['age', 'two_year_recid','c_charge_degree', 'race', 'sex', 'priors_count', 'length_of_stay', 'score_text']]\n",
    "\n",
    "fools = FooLS(protected_class_name='race', protected_class_name_value=['African-American'], unprotected_class_name='score_text', unprotected_class_name_value=['High'], column_flag=ONE_UNCORRELATED_COLUMN, categorical_feature_names=['two_year_recid', 'c_charge_degree', 'sex', 'race'], pd_dataset=dataset)\n",
    "_,_ = fools.LIME_execute()\n",
    "_,_ = fools.SHAP_execute()\n",
    "fools.PDP_execute(fool_method=METHOD_LIME)\n",
    "fools.PDP_execute(fool_method=METHOD_SHAP)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8beb7309",
   "metadata": {},
   "source": [
    "## German Loan Dataset\n",
    "Check if our Framework gets similar results on the datasets provided in the paper - it does!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7549eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(\"data/german_processed.csv\")\n",
    "dataset = dataset.drop([\"PurposeOfLoan\"], axis=1)\n",
    "features = [c for c in dataset]\n",
    "loan_rate_indc = features.index('LoanRateAsPercentOfIncome')\n",
    "mean_lrpi = np.mean(dataset.values[:,loan_rate_indc])\n",
    "loan_boolean = [1 if x[loan_rate_indc] > mean_lrpi else 0 for x in dataset.values]\n",
    "dataset.drop([\"LoanRateAsPercentOfIncome\"], axis=1)\n",
    "dataset['LoanRateAsPercentOfIncome'] = loan_boolean\n",
    "categorical = ['Gender', 'ForeignWorker', 'Single', 'HasTelephone','CheckingAccountBalance_geq_0','CheckingAccountBalance_geq_200','SavingsAccountBalance_geq_100','SavingsAccountBalance_geq_500','MissedPayments','NoCurrentLoan','CriticalAccountOrLoansElsewhere','OtherLoansAtBank','OtherLoansAtStore','HasCoapplicant','HasGuarantor','OwnsHouse','RentsHouse','Unemployed','YearsAtCurrentJob_lt_1','YearsAtCurrentJob_geq_4','JobClassIsSkilled']\n",
    "\n",
    "fools = FooLS(protected_class_name='Gender', protected_class_name_value=['Female'], unprotected_class_name='GoodCustomer', unprotected_class_name_value=[1], column_flag=ONE_EXISTING_COLUMN, correlated_column='LoanRateAsPercentOfIncome', categorical_feature_names=categorical, pd_dataset=dataset)\n",
    "_,_ = fools.LIME_execute()\n",
    "_,_ = fools.SHAP_execute()\n",
    "fools.PDP_execute(fool_method=METHOD_LIME)\n",
    "fools.PDP_execute(fool_method=METHOD_SHAP)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee07769a",
   "metadata": {},
   "source": [
    "## Boston Housing Dataset\n",
    "Apply our framework on a new dataset to examine its applicability. The results indicate so!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c37fd41",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_bh = pd.read_csv(\"data/boston_housing.csv\", index_col=0)\n",
    "\n",
    "# we categorize the price into high and low\n",
    "# and we do the same with the variable black\n",
    "threshold = 50\n",
    "y_col = 'medv'\n",
    "\n",
    "# obtain both 50th percentile of both variables\n",
    "y = pd_bh[y_col]\n",
    "y_cutoff = np.percentile(y, threshold)\n",
    "black_cutoff = np.percentile(pd_bh['black'], threshold)\n",
    "pd_bh = pd_bh.drop([y_col], axis=1)\n",
    "\n",
    "cols = [c for c in pd_bh]\n",
    "# we cut both variables in 50th percentile\n",
    "pd_bh['black'] = np.array([0 if val > black_cutoff else 1 for val in pd_bh['black']])\n",
    "y = np.array([1 if val > y_cutoff else 0 for val in y])\n",
    "pd_bh['medv'] = y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb595bc3",
   "metadata": {},
   "source": [
    "## LIME, SHAP, PDP Default Settings\n",
    "We observe that:<br>\n",
    "The fidility of the LIME approach is always higher than the fidility of the SHAP approach.<br>\n",
    "The LIME approach makes the chosen feature in all iterations the most important feature with a value of 1.0.<br>\n",
    "The SHAP approach makes the chosen feature also the most important feature (\\~0.90). However, it does not achieve the high importance that LIME does.<br>\n",
    "The sensitive feature does not have a high importance when using LIME, even in the 2nd and 3rd rank (\\~0.05).<br>\n",
    "The sensitive feature has a rather high importance when using SHAP on the 2nd and 3rd rank (\\~0.30).<br>\n",
    "The SHAP summary plot shows that all in all, the influence of the sensitive feature is successfully shifted to the chosen feature. However, the sensitive feature is still the 2nd most influencial feature (with a large difference to the 1st most influencial feature).<br>\n",
    "The PDP plot could not be fooled by the adversarial models.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b89de521",
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range(3):\n",
    "    fools = FooLS(protected_class_name='black', protected_class_name_value=[1], unprotected_class_name='medv', unprotected_class_name_value=[1], column_flag=ONE_UNCORRELATED_COLUMN, categorical_feature_names=['chas'], pd_dataset=pd_bh)\n",
    "    print(\"---------------------\")\n",
    "    print(\"Iteration:\",_+1,\"; Used seed:\", fools.seed)\n",
    "    print(\"---------------------\\n\")\n",
    "    _,_ = fools.LIME_execute()\n",
    "    _,_ = fools.SHAP_execute()\n",
    "    fools.PDP_execute(fool_method=METHOD_LIME)\n",
    "    fools.PDP_execute(fool_method=METHOD_SHAP)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2db37e14",
   "metadata": {},
   "source": [
    "## Testing hyperparameters in LIME\n",
    "In this case we are going to change the perturbation std and the perturbation multiplier in the perturbation algorithm and the number of random forest estimators in the local model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd481e36",
   "metadata": {},
   "source": [
    "### Changing std of the perturbation\n",
    "We observe that:<br>\n",
    "The fidility is not strongly affected (always > 0.98).<br>\n",
    "The 1st most important feature is always the chosen feature nearly with a weight of 1.0.<br>\n",
    "Interestingly, when using a standard derivation of 100 the importance of the sensitive feature on the 2nd and 3rd place is strongly increased (from next to nothing to \\~0.40)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "291bd112",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for _ in range(3):\n",
    "    fools = FooLS(protected_class_name='black', protected_class_name_value=[1], unprotected_class_name='medv', unprotected_class_name_value=[1], column_flag=ONE_UNCORRELATED_COLUMN, categorical_feature_names=['chas'], pd_dataset=pd_bh)\n",
    "    print(\"---------------------\")\n",
    "    print(\"Iteration:\",_+1,\"; Used seed:\", fools.seed)\n",
    "    print(\"---------------------\\n\")\n",
    "    for std in [0.1,0.3,0.5,1,10,100]:\n",
    "        print(\"standard derivation of:\", std)\n",
    "        _,_ = fools.LIME_execute(perturbation_std=std)\n",
    "        print(\"---------------------\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9918562b",
   "metadata": {},
   "source": [
    "### Changing perturbation multiplier\n",
    "We observe that:<br>\n",
    "The fidility is not strongly affected (always > 0.98).<br>\n",
    "The 1st most important feature is always the chosen feature nearly with a weight of 1.0.<br>\n",
    "Also, the sensitive feature does not have a high importance at all (even on the 2nd and 3rd rank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e004374",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for _ in range(3):\n",
    "    fools = FooLS(protected_class_name='black', protected_class_name_value=[1], unprotected_class_name='medv', unprotected_class_name_value=[1], column_flag=ONE_UNCORRELATED_COLUMN, categorical_feature_names=['chas'], pd_dataset=pd_bh)\n",
    "    print(\"---------------------\")\n",
    "    print(\"Iteration:\",_+1,\"; Used seed:\", fools.seed)\n",
    "    print(\"---------------------\\n\")\n",
    "    for pm in [1,10,30,60,100,1000]:\n",
    "        print(\"permutation multiplier of :\", pm)\n",
    "        _,_ = fools.LIME_execute(perturbation_multiplier=pm)\n",
    "        print(\"---------------------\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "253895de",
   "metadata": {},
   "source": [
    "### Changing the number of random forest estimators\n",
    "We observe that:<br>\n",
    "The fidility is not strongly affected (always > 0.98).<br>\n",
    "The 1st most important feature is always the chosen feature nearly with a weight of 1.0.<br>\n",
    "Also, the sensitive feature does not have a high importance at all (even on the 2nd and 3rd rank)\n",
    "Very similar to results when changing the permutation multiplier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c930a5e8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for _ in range(3):\n",
    "    fools = FooLS(protected_class_name='black', protected_class_name_value=[1], unprotected_class_name='medv', unprotected_class_name_value=[1], column_flag=ONE_UNCORRELATED_COLUMN, categorical_feature_names=['chas'], pd_dataset=pd_bh)\n",
    "    print(\"---------------------\")\n",
    "    print(\"Iteration:\",_+1,\"; Used seed:\", fools.seed)\n",
    "    print(\"---------------------\\n\")\n",
    "    for rf in [10,50,100,200,300,1000]:\n",
    "        print(\"random forrest estimator amount:\", rf)\n",
    "        fools.LIME_execute(rf_estimators=rf)\n",
    "        print(\"---------------------\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bb60f11",
   "metadata": {},
   "source": [
    "## Testing hyperparameters in SHAP\n",
    "In this case we are going to change the number of kmean clusters and the perturbation multiplier in the pertubation algorithm and the number of random forest estimators in the local model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eac36ea9",
   "metadata": {},
   "source": [
    "### Changing amount of k-means clusters\n",
    "We observe that:<br>\n",
    "With increasing amount of clusters the fidility drops strongly (from \\~1.0 to \\~0.83).<br>\n",
    "The model successfully shifted the importance from the sensitive feature to the chosen feature on the 1st rank.<br>\n",
    "With increasing amount of clusters the importance of the sensitive feature on the 2nd and 3rd rank is strongly increased (from next to nothing to up to \\~0.92).<br>\n",
    "The summary plot shows the steady increase of the sensitive feature influence with increasing number of clusters.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e96f79b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range(3):\n",
    "    fools = FooLS(protected_class_name='black', protected_class_name_value=[1], unprotected_class_name='medv', unprotected_class_name_value=[1], column_flag=ONE_UNCORRELATED_COLUMN, categorical_feature_names=['chas'], pd_dataset=pd_bh)\n",
    "    print(\"---------------------\")\n",
    "    print(\"Iteration:\",_+1,\"; Used seed:\", fools.seed)\n",
    "    print(\"---------------------\\n\")\n",
    "    for n_kmeans in [1,5,10,50,100,200]:\n",
    "        print (\"We are using\", n_kmeans, \"K-mean clusters\")\n",
    "        fools.SHAP_execute(cluster=n_kmeans)\n",
    "        print(\"---------------------\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e6577cb",
   "metadata": {},
   "source": [
    "### Changing the perturbation multiplier\n",
    "We observe that:<br>\n",
    "With a higher perturbation multiplier the fidility rises (from \\~0.65 to \\~0.9).<br>\n",
    "The model successfully shifted the importance from the sensitive feature to the chosen feature on the 1st rank.<br>\n",
    "With a higher perturbation multiplier the importance of the sensitive feature on the 2nd and 3rd rank is increased (from next to nothing to up to \\~0.50).<br>\n",
    "The summary plot shows the steady increase of the sensitive feature influence with a higher perturbation multiplier.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f60f7779",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for _ in range(3):\n",
    "    fools = FooLS(protected_class_name='black', protected_class_name_value=[1], unprotected_class_name='medv', unprotected_class_name_value=[1], column_flag=ONE_UNCORRELATED_COLUMN, categorical_feature_names=['chas'], pd_dataset=pd_bh)\n",
    "    print(\"---------------------\")\n",
    "    print(\"Iteration:\",_+1,\"; Used seed:\", fools.seed)\n",
    "    print(\"---------------------\\n\")\n",
    "    for pm in [1,5,10,50,100,200]:\n",
    "        print (\"We are using a perturbation multiplier of\", pm)\n",
    "        fools.SHAP_execute(perturbation_multiplier=pm)\n",
    "        print(\"---------------------\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19242c2a",
   "metadata": {},
   "source": [
    "### Changing the number of random forest estimators\n",
    "We observe that:<br>\n",
    "The amount of random forest estimators has no significant influence regarding fidility, importance of the sensitive feature on a specific rank or the overall importance of the sensitive feature.<br>\n",
    "The model successfully shifted the importance from the sensitive feature to the chosen feature on the 1st rank.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4f7c000",
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range(3):\n",
    "    fools = FooLS(protected_class_name='black', protected_class_name_value=[1], unprotected_class_name='medv', unprotected_class_name_value=[1], column_flag=ONE_UNCORRELATED_COLUMN, categorical_feature_names=['chas'], pd_dataset=pd_bh)\n",
    "    print(\"---------------------\")\n",
    "    print(\"Iteration:\",_+1,\"; Used seed:\", fools.seed)\n",
    "    print(\"---------------------\\n\")\n",
    "    for rf in [10,50,100,200,500]:\n",
    "        print (\"We are using\", rf, \"random forest multipliers\")\n",
    "        fools.SHAP_execute(rf_estimators=rf)\n",
    "        print(\"---------------------\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b90f2550",
   "metadata": {},
   "source": [
    "## Testing Perturbation Methods for LIME\n",
    "In addition to the standard perturbation method we also introduce two other perturbation methods."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88627386",
   "metadata": {},
   "source": [
    "### Changing Perturbation Method to Soft Brownian Offset\n",
    "The change to SBO does not really have an impact on LIME results. Fidility is the same, importance of the sensitive feature does not change significantly, and the sensitive features influence is successfully shifted towards the chosen feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6306489",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for _ in range(3):\n",
    "    fools = FooLS(protected_class_name='black', protected_class_name_value=[1], unprotected_class_name='medv', unprotected_class_name_value=[1], column_flag=ONE_UNCORRELATED_COLUMN, categorical_feature_names=['chas'], pd_dataset=pd_bh, perturbation_lime_mode=PERTURB_LIME_MODE_SBO)\n",
    "    print(\"---------------------\")\n",
    "    print(\"Iteration:\",_+1,\"; Used seed:\", fools.seed)\n",
    "    print(\"---------------------\\n\")\n",
    "    _, _ = fools.LIME_execute()\n",
    "    print(\"---------------------\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2805445",
   "metadata": {},
   "source": [
    "### Changing Perturbation Method to Gaussian Hyperspheric Offset\n",
    "Fidility is the same when using GHO. However, the sensitive feature's influence is significantly higher than in the standard approach. This can especially be seen in the 2nd and 3rd feature rank, while the 1st feature rank is mostly unaffected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bddb5f7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for _ in range(3):\n",
    "    fools = FooLS(protected_class_name='black', protected_class_name_value=[1], unprotected_class_name='medv', unprotected_class_name_value=[1], column_flag=ONE_UNCORRELATED_COLUMN, categorical_feature_names=['chas'], pd_dataset=pd_bh, perturbation_lime_mode=PERTURB_LIME_MODE_GHO)\n",
    "    print(\"---------------------\")\n",
    "    print(\"Iteration:\",_+1,\"; Used seed:\", fools.seed)\n",
    "    print(\"---------------------\\n\")\n",
    "    _, _ = fools.LIME_execute()\n",
    "    print(\"---------------------\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6ed8f03",
   "metadata": {},
   "source": [
    "## Testing Perturbation Methods for SHAP\n",
    "In addition to the standard perturbation method we also introduce another perturbation method."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d29f1de0",
   "metadata": {},
   "source": [
    "### Changing Perturbation Method to BIRCH\n",
    "The fidility is slightly lower compared to when we use the standard approach. Also, the 1st rank feature is still the chosen feature but the sensitive feature is still unusual high up with it. In addition to that the sensitive feature is a very influencial feature on the 2nd feature rank. In total it is roughly half as influencial as the chosen feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db8e33af",
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range(3):\n",
    "    fools = FooLS(protected_class_name='black', protected_class_name_value=[1], unprotected_class_name='medv', unprotected_class_name_value=[1], column_flag=ONE_UNCORRELATED_COLUMN, categorical_feature_names=['chas'], pd_dataset=pd_bh, perturbation_shap_mode=PERTURB_SHAP_MODE_BIRCH)\n",
    "    print(\"---------------------\")\n",
    "    print(\"Iteration:\",_+1,\"; Used seed:\", fools.seed)\n",
    "    print(\"---------------------\\n\")\n",
    "    _, _ = fools.SHAP_execute()\n",
    "    print(\"---------------------\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80ddf3d5",
   "metadata": {},
   "source": [
    "## New Dataset: MSGEmployees\n",
    "The LIME approach works without problems on this dataset but the SHAP approach has far less success. This could be because of the large amount of categorical data which is not taken into consideration in the LIME approach but in the SHAP approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b45d41e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd_mfg = pd.read_csv(\"data/MFGEmployees.csv\", index_col=0)\n",
    "pd_mfg = pd_mfg.dropna()\n",
    "\n",
    "threshold = 50\n",
    "y_col = 'AbsentHours'\n",
    "\n",
    "pd_mfg = pd_mfg.loc[:1000, :]\n",
    "\n",
    "# obtain both 50th percentile \n",
    "y = pd_mfg[y_col]\n",
    "y_cutoff = np.percentile(y, threshold)\n",
    "pd_mfg = pd_mfg.drop([y_col, 'Surname', 'GivenName'], axis=1)\n",
    "\n",
    "\n",
    "y = np.array([1 if val > y_cutoff else 0 for val in y])\n",
    "pd_mfg['AbsentHours'] = y\n",
    "\n",
    "categorical = ['Gender','City','JobTitle','DepartmentName','Division','AbsentHours','BusinessUnit']\n",
    "for _ in range(3):\n",
    "    fools = FooLS(protected_class_name='Gender', protected_class_name_value=['F'], unprotected_class_name='AbsentHours', unprotected_class_name_value=[1], column_flag=ONE_UNCORRELATED_COLUMN, categorical_feature_names=categorical, pd_dataset=pd_mfg)\n",
    "    print(\"---------------------\")\n",
    "    print(\"Iteration:\",_+1,\"; Used seed:\", fools.seed)\n",
    "    print(\"---------------------\\n\")\n",
    "    _,_ = fools.LIME_execute()\n",
    "    _,_ = fools.SHAP_execute()\n",
    "    fools.PDP_execute()\n",
    "    print(\"---------------------\\n\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94f3a919",
   "metadata": {},
   "source": [
    "## New Dataset: Telecust\n",
    "The fidility of SHAP in this model is not very good. It is roughly 0.64 which means that the new model might come up with other predictions than the original one. Since the approach works on all other datasets it is most likely caused by the categorical features in this dataset. Since LIME does have a fidility close to 1.0 and does not use categorical features it can be assumed the categorical features in this dataset are problematic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8111083",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd_te = pd.read_csv(\"data/telecust.csv\")\n",
    "pd_te = pd_te.dropna()\n",
    "\n",
    "pd_te = pd_te.drop(columns=['ed'])\n",
    "\n",
    "for _ in range(3):\n",
    "    fools = FooLS(protected_class_name='gender', protected_class_name_value=[0], unprotected_class_name='custcat', unprotected_class_name_value=['A', 'B'], column_flag=1, categorical_feature_names=['marital','gender','unrelated_column1'], pd_dataset=pd_te)\n",
    "    print(\"---------------------\")\n",
    "    print(\"Iteration:\",_+1,\"; Used seed:\", fools.seed)\n",
    "    print(\"---------------------\\n\")\n",
    "    _,_ = fools.LIME_execute()\n",
    "    _,_ = fools.SHAP_execute()\n",
    "    fools.PDP_execute(fool_method=METHOD_LIME)\n",
    "    print(\"---------------------\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc9d17b1",
   "metadata": {},
   "source": [
    "# Unittests\n",
    "To make sure that changes in our framework do not destroy functionalities we introduced unittests. The unittests are all applied on the boston housing dataset because the functionality does not change if other datasets are used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40814fa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import unittest\n",
    "def warn(*args, **kwargs):\n",
    "    pass\n",
    "import warnings\n",
    "warnings.warn = warn\n",
    "\n",
    "pd_bh = pd.read_csv(\"data/boston_housing.csv\", index_col=0)\n",
    "        \n",
    "# we categorize the price into high and low\n",
    "# and we do the same with the variable black\n",
    "threshold = 50\n",
    "y_col = 'medv'\n",
    "\n",
    "# obtain both 50th percentile of both variables\n",
    "y = pd_bh[y_col]\n",
    "y_cutoff = np.percentile(y, threshold)\n",
    "black_cutoff = np.percentile(pd_bh['black'], threshold)\n",
    "pd_bh = pd_bh.drop([y_col], axis=1)\n",
    "\n",
    "cols = [c for c in pd_bh]\n",
    "# we cut both variables in 50th percentile\n",
    "pd_bh['black'] = np.array([0 if val > black_cutoff else 1 for val in pd_bh['black']])\n",
    "y = np.array([1 if val > y_cutoff else 0 for val in y])\n",
    "pd_bh['medv'] = y\n",
    "unittest.TestLoader.sortTestMethodsUsing = None\n",
    "class TestNotebook(unittest.TestCase):\n",
    "    \n",
    "    def test_existing_column_no_column_name(self):\n",
    "        with self.assertRaises(Exception) as context:\n",
    "            fools = FooLS(protected_class_name='black', protected_class_name_value=[1], unprotected_class_name='medv', unprotected_class_name_value=[1], column_flag=ONE_EXISTING_COLUMN, correlated_column=None, categorical_feature_names=['chas'], pd_dataset=pd_bh)\n",
    "        self.assertTrue('You need to provide a column name if you want to shift importance' in str(context.exception))\n",
    "    \n",
    "    def test_no_pandas_dataset(self):\n",
    "        with self.assertRaises(Exception) as context:\n",
    "            fools = FooLS(protected_class_name='black', protected_class_name_value=[1], unprotected_class_name='medv', unprotected_class_name_value=[1], column_flag=2, categorical_feature_names=['chas'], pd_dataset='nopadas')\n",
    "        self.assertTrue('The dataset needs to be a Pandas Dataframe' in str(context.exception))\n",
    "    def test_column_not_in_dataset(self):\n",
    "        with self.assertRaises(Exception) as context:\n",
    "            fools = FooLS(protected_class_name='black', protected_class_name_value=[1], unprotected_class_name='medv', unprotected_class_name_value=[1], column_flag=2, correlated_column='invalid', categorical_feature_names=['chas'], pd_dataset=pd_bh)\n",
    "        self.assertTrue('You need to provide an existing column that is part of the' in str(context.exception))\n",
    "    def test_column_flag_invalid(self):\n",
    "        with self.assertRaises(Exception) as context:\n",
    "            fools = FooLS(protected_class_name='black', protected_class_name_value=[1], unprotected_class_name='medv', unprotected_class_name_value=[1], column_flag=999, categorical_feature_names=['chas'], pd_dataset=pd_bh)\n",
    "        self.assertTrue('Only three modes available: Use an existing' in str(context.exception))\n",
    "    def test_perturbation_mode_invalid(self):\n",
    "        with self.assertRaises(Exception) as context:\n",
    "            fools = FooLS(protected_class_name='black', protected_class_name_value=[1], unprotected_class_name='medv', unprotected_class_name_value=[1], column_flag=2, categorical_feature_names=['chas'], pd_dataset=pd_bh, perturbation_lime_mode = 999)\n",
    "        self.assertTrue('Only three perturbation methods available' in str(context.exception))\n",
    "    def test_class_names_not_str(self):\n",
    "        with self.assertRaises(Exception) as context:\n",
    "            fools = FooLS(protected_class_name=123, protected_class_name_value=[1], unprotected_class_name='medv', unprotected_class_name_value=[1], column_flag=2, categorical_feature_names=['chas'], pd_dataset=pd_bh)\n",
    "        self.assertTrue('You need to provide the names' in str(context.exception))\n",
    "    def test_class_name_values_not_list(self):\n",
    "        with self.assertRaises(Exception) as context:\n",
    "            fools = FooLS(protected_class_name='black', protected_class_name_value=1, unprotected_class_name='medv', unprotected_class_name_value=[1], column_flag=2, categorical_feature_names=['chas'], pd_dataset=pd_bh)\n",
    "        self.assertTrue('You need to provide the values' in str(context.exception))\n",
    "    def test_correlated_column(self):\n",
    "        fools = FooLS(protected_class_name='black', protected_class_name_value=[1], unprotected_class_name='medv', unprotected_class_name_value=[1], column_flag=0, correlated_column='rad', categorical_feature_names=['chas'], pd_dataset=pd_bh)\n",
    "        result = True if 'rad' in fools.features and 'unrelated_column1' not in fools.features and 'unrelated_column2' not in fools.features else False\n",
    "        self.assertEqual(result, True)\n",
    "    def test_one_uncorrelated_column(self):\n",
    "        fools = FooLS(protected_class_name='black', protected_class_name_value=[1], unprotected_class_name='medv', unprotected_class_name_value=[1], column_flag=1, categorical_feature_names=['chas'], pd_dataset=pd_bh)\n",
    "        result = True if 'unrelated_column1' in fools.features and 'unrelated_column2' not in fools.features else False\n",
    "        self.assertEqual(result, True)\n",
    "    def test_two_uncorrelated_column(self):\n",
    "        fools = FooLS(protected_class_name='black', protected_class_name_value=[1], unprotected_class_name='medv', unprotected_class_name_value=[1], column_flag=2, categorical_feature_names=['chas'], pd_dataset=pd_bh)\n",
    "        result = True if 'unrelated_column1' in fools.features and 'unrelated_column2' in fools.features else False\n",
    "        self.assertEqual(result, True)\n",
    "    def test_correlated_LIME(self):\n",
    "        fools = FooLS(protected_class_name='black', protected_class_name_value=[1], unprotected_class_name='medv', unprotected_class_name_value=[1], column_flag=0, correlated_column='rad', categorical_feature_names=['chas'], pd_dataset=pd_bh)\n",
    "        adv_model, explanation = fools.LIME_execute(verbose=False)\n",
    "        rad_importance = 0\n",
    "        black_importance = 0\n",
    "        for feat in explanation[1]:\n",
    "            if feat[0] == 'rad':\n",
    "                rad_importance = feat[1]\n",
    "            elif feat[0] == 'black':\n",
    "                black_importance = feat[1]\n",
    "        result = True if rad_importance > black_importance else False\n",
    "        fidiliy = True if round(adv_model.fidelity(fools.xtest),2) > 0.9 else False\n",
    "        self.assertEqual(result, True)\n",
    "        self.assertEqual(fidiliy, True)\n",
    "    def test_one_uncorrelated_LIME(self):\n",
    "        fools = FooLS(protected_class_name='black', protected_class_name_value=[1], unprotected_class_name='medv', unprotected_class_name_value=[1], column_flag=1, categorical_feature_names=['chas'], pd_dataset=pd_bh)\n",
    "        adv_model, explanation = fools.LIME_execute(verbose=False)\n",
    "        uncorrelated_importance = 0\n",
    "        black_importance = 0\n",
    "        for feat in explanation[1]:\n",
    "            if feat[0] == 'unrelated_column1':\n",
    "                uncorrelated_importance = feat[1]\n",
    "            elif feat[0] == 'black':\n",
    "                black_importance = feat[1]\n",
    "        result = True if uncorrelated_importance > black_importance else False\n",
    "        fidiliy = True if round(adv_model.fidelity(fools.xtest),2) > 0.9 else False\n",
    "        self.assertEqual(result, True)\n",
    "        self.assertEqual(fidiliy, True)\n",
    "    def test_two_uncorrelated_LIME(self):\n",
    "        fools = FooLS(protected_class_name='black', protected_class_name_value=[1], unprotected_class_name='medv', unprotected_class_name_value=[1], column_flag=2, categorical_feature_names=['chas'], pd_dataset=pd_bh)\n",
    "        adv_model, explanation = fools.LIME_execute(verbose=False)\n",
    "        uncorrelated1_importance = 0\n",
    "        uncorrelated2_importance = 0\n",
    "        black_importance = 0\n",
    "        for feat in explanation[1]:\n",
    "            if feat[0] == 'unrelated_column1':\n",
    "                uncorrelated1_importance = feat[1]\n",
    "            elif feat[0] == 'unrelated_column2':\n",
    "                uncorrelated2_importance = feat[1]\n",
    "            elif feat[0] == 'black':\n",
    "                black_importance = feat[1]\n",
    "        result = True if uncorrelated1_importance+uncorrelated2_importance > black_importance else False\n",
    "        fidiliy = True if round(adv_model.fidelity(fools.xtest),2) > 0.9 else False\n",
    "        self.assertEqual(result, True)\n",
    "        self.assertEqual(fidiliy, True)\n",
    "    def test_correlated_SHAP(self):\n",
    "        fools = FooLS(protected_class_name='black', protected_class_name_value=[1], unprotected_class_name='medv', unprotected_class_name_value=[1], column_flag=0, correlated_column='rad', categorical_feature_names=['chas'], pd_dataset=pd_bh)\n",
    "        adv_model, explanation = fools.SHAP_execute(verbose=False)\n",
    "        rad_importance = 0\n",
    "        black_importance = 0\n",
    "        for feat in explanation[1]:\n",
    "            if feat[0] == 'rad':\n",
    "                rad_importance = feat[1]\n",
    "            elif feat[0] == 'black':\n",
    "                black_importance = feat[1]\n",
    "        result = True if rad_importance > black_importance else False\n",
    "        fidiliy = True if round(adv_model.fidelity(fools.xtest),2) > 0.8 else False\n",
    "        self.assertEqual(result, True)\n",
    "        self.assertEqual(fidiliy, True)\n",
    "    def test_one_uncorrelated_SHAP(self):\n",
    "        fools = FooLS(protected_class_name='black', protected_class_name_value=[1], unprotected_class_name='medv', unprotected_class_name_value=[1], column_flag=1, categorical_feature_names=['chas'], pd_dataset=pd_bh)\n",
    "        adv_model, explanation = fools.SHAP_execute(verbose=False)\n",
    "        uncorrelated_importance = 0\n",
    "        black_importance = 0\n",
    "        for feat in explanation[1]:\n",
    "            if feat[0] == 'unrelated_column1':\n",
    "                uncorrelated_importance = feat[1]\n",
    "            elif feat[0] == 'black':\n",
    "                black_importance = feat[1]\n",
    "        result = True if uncorrelated_importance > black_importance else False\n",
    "        fidiliy = True if round(adv_model.fidelity(fools.xtest),2) > 0.8 else False\n",
    "        self.assertEqual(result, True)\n",
    "        self.assertEqual(fidiliy, True)\n",
    "    def test_two_uncorrelated_SHAP(self):\n",
    "        fools = FooLS(protected_class_name='black', protected_class_name_value=[1], unprotected_class_name='medv', unprotected_class_name_value=[1], column_flag=2, categorical_feature_names=['chas'], pd_dataset=pd_bh)\n",
    "        adv_model, explanation = fools.SHAP_execute(verbose=False)\n",
    "        uncorrelated1_importance = 0\n",
    "        uncorrelated2_importance = 0\n",
    "        black_importance = 0\n",
    "        for feat in explanation[1]:\n",
    "            if feat[0] == 'unrelated_column1':\n",
    "                uncorrelated1_importance = feat[1]\n",
    "            elif feat[0] == 'unrelated_column2':\n",
    "                uncorrelated2_importance = feat[1]\n",
    "            elif feat[0] == 'black':\n",
    "                black_importance = feat[1]\n",
    "        result = True if uncorrelated1_importance+uncorrelated2_importance > black_importance else False\n",
    "        fidiliy = True if round(adv_model.fidelity(fools.xtest),2) > 0.8 else False\n",
    "        self.assertEqual(result, True)\n",
    "        self.assertEqual(fidiliy, True)\n",
    "    def test_LIME_same_seed(self):\n",
    "        fools1 = FooLS(seed=123454321, protected_class_name='black', protected_class_name_value=[1], unprotected_class_name='medv', unprotected_class_name_value=[1], column_flag=0, correlated_column='rad', categorical_feature_names=['chas'], pd_dataset=pd_bh)\n",
    "        adv_model1, explanation1 = fools1.LIME_execute(verbose=False)\n",
    "        fools2 = FooLS(seed=123454321, protected_class_name='black', protected_class_name_value=[1], unprotected_class_name='medv', unprotected_class_name_value=[1], column_flag=0, correlated_column='rad', categorical_feature_names=['chas'], pd_dataset=pd_bh)\n",
    "        adv_model2, explanation2 = fools2.LIME_execute(verbose=False)\n",
    "        self.assertEqual(explanation1, explanation2)\n",
    "    def test_LIME_different_seed(self):\n",
    "        fools1 = FooLS(seed=123454321, protected_class_name='black', protected_class_name_value=[1], unprotected_class_name='medv', unprotected_class_name_value=[1], column_flag=0, correlated_column='rad', categorical_feature_names=['chas'], pd_dataset=pd_bh)\n",
    "        adv_model1, explanation1 = fools1.LIME_execute(verbose=False)\n",
    "        fools2 = FooLS(seed=999993134, protected_class_name='black', protected_class_name_value=[1], unprotected_class_name='medv', unprotected_class_name_value=[1], column_flag=0, correlated_column='rad', categorical_feature_names=['chas'], pd_dataset=pd_bh)\n",
    "        adv_model2, explanation2 = fools2.LIME_execute(verbose=False)\n",
    "        result = explanation1 == explanation2\n",
    "        self.assertEqual(result, False)\n",
    "\n",
    "unittest.main(argv=[''], verbosity=2, exit=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
